{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-13:\n",
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Process Process-1:\n",
      "Process Process-9:\n",
      "Process Process-8:\n",
      "Process Process-14:\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "Process Process-2:\n",
      "Process Process-16:\n",
      "Traceback (most recent call last):\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "Process Process-15:\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Process Process-6:\n",
      "Process Process-5:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/Desktop/walker-2d/multiprocessing_env.py\", line 11, in worker\n",
      "    cmd, data = remote.recv()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/noa/anaconda3/envs/dml/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pendulum-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test_env(vis=False):\\n    state = env.reset()\\n    if vis: env.render()\\n    done = False\\n    total_reward = 0\\n    while not done:\\n        state = torch.FloatTensor(state).unsqueeze(0).to(device)\\n        dist, _ = model(state)\\n        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\\n        state = next_state\\n        if vis: env.render()\\n        total_reward += reward\\n    return total_reward\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\\n    values = values + [next_value]\\n    gae = 0\\n    returns = []\\n    for step in reversed(range(len(rewards))):\\n        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\\n        gae = delta + gamma * tau * masks[step] * gae\\n        returns.insert(0, gae + values[step])\\n    return returns\\n\\n# Calculate the generalized advantage estimation\\ndef calculate_gae(tau, time_horizon, gamma, advantages):\\n    gaes = []\\n    prev_gae = []\\n\\n    # Start with the last sample and move backwards \\n    for i in range(time_horizon, 0, -1):\\n        advantage = rewards[i] + gamma*state_values[i]*terminal_state[i] - next_state_values[i]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns\n",
    "\n",
    "# Calculate the generalized advantage estimation\n",
    "def calculate_gae(tau, time_horizon, gamma, advantages):\n",
    "    gaes = []\n",
    "    prev_gae = []\n",
    "\n",
    "    # Start with the last sample and move backwards \n",
    "    for i in range(time_horizon, 0, -1):\n",
    "        advantage = rewards[i] + gamma*state_values[i]*terminal_state[i] - next_state_values[i]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\"\"\"\n",
    "\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    \n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            \n",
    "            entropy_coefficient = 0.001\n",
    "            distance,value = model(state)\n",
    "            # Calculating the entropy for the yielded distance\n",
    "            entropy = distance.entropy().mean()\n",
    "            new_log_probs = distance.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            clipped_objective  = - torch.min(ratio*advantage, torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage)\n",
    "            critic_loss = (return_ - value).pow(2)\n",
    "            critic_mean_loss = critic_loss.mean()\n",
    "            actor_mean_loss = clipped_objective.mean()\n",
    "            loss = 0.5 * critic_mean_loss + actor_mean_loss - entropy_coefficient * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 256\n",
    "lr               = 3e-4\n",
    "num_steps        = 20*16\n",
    "mini_batch_size  = 5\n",
    "ppo_epochs       = 4\n",
    "discount_factor = 0.99\n",
    "lambda_ = 0.95\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_to_train_for = 10**6\n",
    "evaluate_every = 10**3\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-da03f2842e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mgaes\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mppo_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-d869e69a3faa>\u001b[0m in \u001b[0;36mppo_update\u001b[0;34m(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_log_probs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mold_log_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0msurr1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mclipped_objective\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0madvantage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mclip_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclip_param\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0madvantage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreturn_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mcritic_mean_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "time_step_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "for time_step in range(time_steps_to_train_for):\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    terminal_states     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for step_counter in range(num_steps):\n",
    "        time_step_counter+=1\n",
    "        \n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        terminal_states.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if time_step_counter % evaluate_every == 0:\n",
    "            print(time_step)\n",
    "            test_reward = np.mean([evaluate_agent(False) for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(time_step_counter, test_rewards)# remove this\n",
    "            #print(test_reward)\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    state_values = values + [next_value]\n",
    "    advantages = calculate_advantage(rewards, state_values, discount_factor, terminal_states)\n",
    "    gaes = calculate_gae(lambda_, num_steps, discount_factor, advantages, terminal_states, state_values)\n",
    "    #returns = compute_gae(next_value, rewards, terminal_states, values)\n",
    "    \n",
    "    \n",
    "\n",
    "    #returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    returns   = (torch.cat(gaes) + values).detach()\n",
    "    gaes      = torch.cat(gaes).detach()\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, gaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This evaluates the agent\n",
    "def evaluate_agent(vis):\n",
    "    if vis: env.render()\n",
    "    state = env.reset()\n",
    "    in_terminal_state = False\n",
    "    total_reward = 0\n",
    "    while not in_terminal_state:\n",
    "        state = torch.FloatTensor(state).reshape(1,-1).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, in_terminal_state, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        #time.sleep(1/60)\n",
    "\n",
    "    #final_location_x = env.robot.get_location()[0]\n",
    "\n",
    "    return total_reward#, final_location_x\n",
    "\n",
    "\n",
    "\n",
    "def calculate_advantage(rewards, state_values, gamma, terminal_state):\n",
    "    # Convert the lists into torch tensors\n",
    "    #print(state_values)\n",
    "    next_values = torch.stack(state_values[1:])\n",
    "    prev_values = torch.stack(state_values[0:-1])\n",
    "    terminal_state = torch.stack(terminal_state)\n",
    "    rewards = torch.stack(rewards)\n",
    "    \n",
    "    # Calculate the advantages\n",
    "    advantage = rewards + gamma*next_values*terminal_state - prev_values\n",
    "    return advantage\n",
    "\n",
    "\"\"\"\n",
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the generalized advantage estimation\n",
    "def calculate_gae(lambda_, num_steps, gamma, advantages, terminal_states, state_values):\n",
    "    gaes = []\n",
    "    prev_gae = 0\n",
    "    \n",
    "    # Convert the lists to tensors\n",
    "    terminal_states = torch.stack(terminal_states)\n",
    "\n",
    "    # Start with the last sample and move backwards \n",
    "    for i in range(num_steps-1, -1, -1):\n",
    "        gae = advantages[i] + gamma*lambda_*terminal_states[i]*prev_gae\n",
    "        #gaes.insert(0, gae)\n",
    "        gaes.append(gae)\n",
    "        prev_gae = gae\n",
    "        \n",
    "    # The list in the backwards order. Return it flipped\n",
    "    return gaes[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
