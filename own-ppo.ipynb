{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Use CUDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Create Environments</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing_env import SubprocVecEnv\n",
    "\n",
    "num_envs = 16\n",
    "env_name = \"Pendulum-v0\"\n",
    "\n",
    "def make_env():\n",
    "    def _thunk():\n",
    "        env = gym.make(env_name)\n",
    "        return env\n",
    "\n",
    "    return _thunk\n",
    "\n",
    "envs = [make_env() for i in range(num_envs)]\n",
    "envs = SubprocVecEnv(envs)\n",
    "\n",
    "env = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Neural Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.normal_(m.weight, mean=0., std=0.1)\n",
    "        nn.init.constant_(m.bias, 0.1)\n",
    "        \n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, hidden_size, std=0.0):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(num_inputs, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_outputs),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.log_std = nn.Parameter(torch.ones(1, num_outputs) * std)\n",
    "        \n",
    "        self.apply(init_weights)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        value = self.critic(x)\n",
    "        mu    = self.actor(x)\n",
    "        std   = self.log_std.exp().expand_as(mu)\n",
    "        dist  = Normal(mu, std)\n",
    "        return dist, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef test_env(vis=False):\\n    state = env.reset()\\n    if vis: env.render()\\n    done = False\\n    total_reward = 0\\n    while not done:\\n        state = torch.FloatTensor(state).unsqueeze(0).to(device)\\n        dist, _ = model(state)\\n        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\\n        state = next_state\\n        if vis: env.render()\\n        total_reward += reward\\n    return total_reward\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def plot(frame_idx, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, rewards[-1]))\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "def test_env(vis=False):\n",
    "    state = env.reset()\n",
    "    if vis: env.render()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, done, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        if vis: env.render()\n",
    "        total_reward += reward\n",
    "    return total_reward\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>GAE</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\\n    values = values + [next_value]\\n    gae = 0\\n    returns = []\\n    for step in reversed(range(len(rewards))):\\n        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\\n        gae = delta + gamma * tau * masks[step] * gae\\n        returns.insert(0, gae + values[step])\\n    return returns\\n\\n# Calculate the generalized advantage estimation\\ndef calculate_gae(tau, time_horizon, gamma, advantages):\\n    gaes = []\\n    prev_gae = []\\n\\n    # Start with the last sample and move backwards \\n    for i in range(time_horizon, 0, -1):\\n        advantage = rewards[i] + gamma*state_values[i]*terminal_state[i] - next_state_values[i]\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns\n",
    "\n",
    "# Calculate the generalized advantage estimation\n",
    "def calculate_gae(tau, time_horizon, gamma, advantages):\n",
    "    gaes = []\n",
    "    prev_gae = []\n",
    "\n",
    "    # Start with the last sample and move backwards \n",
    "    for i in range(time_horizon, 0, -1):\n",
    "        advantage = rewards[i] + gamma*state_values[i]*terminal_state[i] - next_state_values[i]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Proximal Policy Optimization Algorithm</h1>\n",
    "<h2><a href=\"https://arxiv.org/abs/1707.06347\">Arxiv</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            dist, value = model(state)\n",
    "            entropy = dist.entropy().mean()\n",
    "            new_log_probs = dist.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            surr2 = torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage\n",
    "\n",
    "            actor_loss  = - torch.min(surr1, surr2).mean()\n",
    "            critic_loss = (return_ - value).pow(2).mean()\n",
    "\n",
    "            loss = 0.5 * critic_loss + actor_loss - 0.001 * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\"\"\"\n",
    "\n",
    "def ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantage):\n",
    "    \n",
    "    batch_size = states.size(0)\n",
    "    for _ in range(batch_size // mini_batch_size):\n",
    "        rand_ids = np.random.randint(0, batch_size, mini_batch_size)\n",
    "        yield states[rand_ids, :], actions[rand_ids, :], log_probs[rand_ids, :], returns[rand_ids, :], advantage[rand_ids, :]\n",
    "        \n",
    "        \n",
    "\n",
    "def ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, advantages, clip_param=0.2):\n",
    "    for _ in range(ppo_epochs):\n",
    "        for state, action, old_log_probs, return_, advantage in ppo_iter(mini_batch_size, states, actions, log_probs, returns, advantages):\n",
    "            \n",
    "            entropy_coefficient = 0.001\n",
    "            distance,value = model(state)\n",
    "            # Calculating the entropy for the yielded distance\n",
    "            entropy = distance.entropy().mean()\n",
    "            new_log_probs = distance.log_prob(action)\n",
    "\n",
    "            ratio = (new_log_probs - old_log_probs).exp()\n",
    "            surr1 = ratio * advantage\n",
    "            clipped_objective  = - torch.min(ratio*advantage, torch.clamp(ratio, 1.0 - clip_param, 1.0 + clip_param) * advantage)\n",
    "            critic_loss = (return_ - value).pow(2)\n",
    "            critic_mean_loss = critic_loss.mean()\n",
    "            actor_mean_loss = clipped_objective.mean()\n",
    "            loss = 0.5 * critic_mean_loss + actor_mean_loss - entropy_coefficient * entropy\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs  = envs.observation_space.shape[0]\n",
    "num_outputs = envs.action_space.shape[0]\n",
    "\n",
    "#Hyper params:\n",
    "hidden_size      = 256\n",
    "lr               = 3e-4\n",
    "num_steps        = 20*16\n",
    "mini_batch_size  = 5\n",
    "ppo_epochs       = 4\n",
    "discount_factor = 0.99\n",
    "lambda_ = 0.95\n",
    "\n",
    "model = ActorCritic(num_inputs, num_outputs, hidden_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps_to_train_for = 10**6\n",
    "evaluate_every = 10**3\n",
    "test_rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = envs.reset()\n",
    "time_step_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "for time_step in range(time_steps_to_train_for):\n",
    "\n",
    "    log_probs = []\n",
    "    values    = []\n",
    "    states    = []\n",
    "    actions   = []\n",
    "    rewards   = []\n",
    "    terminal_states     = []\n",
    "    entropy = 0\n",
    "\n",
    "    for step_counter in range(num_steps):\n",
    "        time_step_counter+=1\n",
    "        \n",
    "        state = torch.FloatTensor(state).to(device)\n",
    "        dist, value = model(state)\n",
    "\n",
    "        action = dist.sample()\n",
    "        next_state, reward, done, _ = envs.step(action.cpu().numpy())\n",
    "\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy += dist.entropy().mean()\n",
    "        \n",
    "        log_probs.append(log_prob)\n",
    "        values.append(value)\n",
    "        rewards.append(torch.FloatTensor(reward).unsqueeze(1).to(device))\n",
    "        terminal_states.append(torch.FloatTensor(1 - done).unsqueeze(1).to(device))\n",
    "        \n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        if time_step_counter % evaluate_every == 0:\n",
    "            print(time_step)\n",
    "            test_reward = np.mean([evaluate_agent(False) for _ in range(10)])\n",
    "            test_rewards.append(test_reward)\n",
    "            plot(time_step_counter, test_rewards)# remove this\n",
    "            #print(test_reward)\n",
    "            \n",
    "\n",
    "    next_state = torch.FloatTensor(next_state).to(device)\n",
    "    _, next_value = model(next_state)\n",
    "    state_values = values + [next_value]\n",
    "    advantages = calculate_advantage(rewards, state_values, discount_factor, terminal_states)\n",
    "    gaes = calculate_gae(lambda_, num_steps, discount_factor, advantages, terminal_states, state_values)\n",
    "    #returns = compute_gae(next_value, rewards, terminal_states, values)\n",
    "    \n",
    "    \n",
    "\n",
    "    #returns   = torch.cat(returns).detach()\n",
    "    log_probs = torch.cat(log_probs).detach()\n",
    "    values    = torch.cat(values).detach()\n",
    "    states    = torch.cat(states)\n",
    "    actions   = torch.cat(actions)\n",
    "    returns   = (torch.cat(gaes) + values).detach()\n",
    "    gaes      = torch.cat(gaes).detach()\n",
    "    \n",
    "    ppo_update(ppo_epochs, mini_batch_size, states, actions, log_probs, returns, gaes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This evaluates the agent\n",
    "def evaluate_agent(vis):\n",
    "    if vis: env.render()\n",
    "    state = env.reset()\n",
    "    in_terminal_state = False\n",
    "    total_reward = 0\n",
    "    while not in_terminal_state:\n",
    "        state = torch.FloatTensor(state).reshape(1,-1).to(device)\n",
    "        dist, _ = model(state)\n",
    "        next_state, reward, in_terminal_state, _ = env.step(dist.sample().cpu().numpy()[0])\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        #time.sleep(1/60)\n",
    "\n",
    "    #final_location_x = env.robot.get_location()[0]\n",
    "\n",
    "    return total_reward#, final_location_x\n",
    "\n",
    "\n",
    "\n",
    "def calculate_advantage(rewards, state_values, gamma, terminal_state):\n",
    "    # Convert the lists into torch tensors\n",
    "    #print(state_values)\n",
    "    next_values = torch.stack(state_values[1:])\n",
    "    prev_values = torch.stack(state_values[0:-1])\n",
    "    terminal_state = torch.stack(terminal_state)\n",
    "    rewards = torch.stack(rewards)\n",
    "    \n",
    "    # Calculate the advantages\n",
    "    advantage = rewards + gamma*next_values*terminal_state - prev_values\n",
    "    return advantage\n",
    "\n",
    "\"\"\"\n",
    "def compute_gae(next_value, rewards, masks, values, gamma=0.99, tau=0.95):\n",
    "    values = values + [next_value]\n",
    "    gae = 0\n",
    "    returns = []\n",
    "    for step in reversed(range(len(rewards))):\n",
    "        delta = rewards[step] + gamma * values[step + 1] * masks[step] - values[step]\n",
    "        gae = delta + gamma * tau * masks[step] * gae\n",
    "        returns.insert(0, gae + values[step])\n",
    "    return returns\n",
    "\"\"\"\n",
    "\n",
    "# Calculate the generalized advantage estimation\n",
    "def calculate_gae(lambda_, num_steps, gamma, advantages, terminal_states, state_values):\n",
    "    gaes = []\n",
    "    prev_gae = 0\n",
    "    \n",
    "    # Convert the lists to tensors\n",
    "    terminal_states = torch.stack(terminal_states)\n",
    "\n",
    "    # Start with the last sample and move backwards \n",
    "    for i in range(num_steps-1, -1, -1):\n",
    "        gae = advantages[i] + gamma*lambda_*terminal_states[i]*prev_gae\n",
    "        #gaes.insert(0, gae)\n",
    "        gaes.append(gae)\n",
    "        prev_gae = gae\n",
    "        \n",
    "    # The list in the backwards order. Return it flipped\n",
    "    return gaes[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Saving trajectories for GAIL</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "\n",
    "max_expert_num = 50000\n",
    "num_steps = 0\n",
    "expert_traj = []\n",
    "\n",
    "for i_episode in count():\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        dist, _ = model(state)\n",
    "        action = dist.sample().cpu().numpy()[0]\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        expert_traj.append(np.hstack([state, action]))\n",
    "        num_steps += 1\n",
    "    \n",
    "    print(\"episode:\", i_episode, \"reward:\", total_reward)\n",
    "    \n",
    "    if num_steps >= max_expert_num:\n",
    "        break\n",
    "        \n",
    "expert_traj = np.stack(expert_traj)\n",
    "print()\n",
    "print(expert_traj.shape)\n",
    "print()\n",
    "np.save(\"expert_traj.npy\", expert_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
